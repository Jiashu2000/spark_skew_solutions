## Summarization of Solutions to Data Skew in Apache Spark

### Jiashu Chen

Apache Spark is a big data computing framework for parallel data processing on computer clusters. Spark is developed based on the concept of Resilient Distributed Dataset (RDD), which allows in-memory computation on large clusters in a fault-tolerant manner \cite{spark_original_paper}. Sparkâ€™s in-memory computing capability makes it ten to a hundred times faster than the disk-based Hadoop MapReduce system, especially for iterative algorithms and interactive data mining tasks. Even though Spark is known for its fast in-memory computation, its performance could degrade due to data skew. This project first provides a summarization of solutions to address data skew in distributed computing systems based on previous studies. In the experiment part, 9 join queries with skew issues are tested in Spark. Following the analysis of experiment results, insights on skew mitigation are discussed from the viewpoint of a Spark user.
